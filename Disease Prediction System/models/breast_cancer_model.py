# -*- coding: utf-8 -*-
"""Breast_Cancer_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hSlG66B-F9MmEz7OpqzDVvH948BjjzJd
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score
import pickle
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

warnings.filterwarnings("ignore")

# Loading dataset
df = pd.read_csv("breast_cancer_wisconsin_diagnostic.csv")

df.head()

# Separating features and labels
X = df.drop(columns=['Diagnosis'])  # Drop target variable
y = df['Diagnosis']

from imblearn.over_sampling import SMOTE

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X, y = smote.fit_resample(X, y)

#Feature Selection using Recursive Feature Elimination (RFE)
rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=10, step=1)
rfe_selector.fit(X, y)

selected_features = X.columns[rfe_selector.support_]
print("Selected Features:", selected_features)

# Using only selected features
X_selected = X[selected_features]

# Splitting data into training/testing sets
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25, random_state=42)

# Initialize models with scaling and training in pipelines
models = {
    "Logistic Regression (Elastic Net)": Pipeline([
        ("scaler", StandardScaler()),
        ("model", LogisticRegression(
            penalty='elasticnet',
            solver='saga',
            l1_ratio=0.5,
            C=1.0,
            max_iter=1000
        ))
    ]),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "SVC": Pipeline([
        ("scaler", StandardScaler()),
        ("model", SVC(random_state=42))
    ])
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    if isinstance(model, Pipeline) and "model" in model.named_steps:
        model_cv = model
    else:
        # For non-pipeline models, create a temporary pipeline for cross-validation
        model_cv = Pipeline([("scaler", StandardScaler()), ("model", model)])

    cv_scores = cross_val_score(model_cv, X_selected, y, cv=5, scoring='accuracy')

    print(f"\n{name}:")
    print(f"Test Accuracy: {acc:.2f}")
    print(f"Cross-Validation Accuracy: {cv_scores.mean():.2f} Â± {cv_scores.std():.2f}")

# Save the best-performing model (Logistic Regression in this case)
best_model = models["Logistic Regression (Elastic Net)"]
pickle.dump(best_model, open("logistic_regression_Breast_Cancer_model.pkl", "wb"))

print("\nModel saved as 'logistic_regression_Breast_Cancer_model.pkl'")

