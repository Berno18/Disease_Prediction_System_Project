# -*- coding: utf-8 -*-
"""Heart_disease_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dzoavOGApwt-sTA-B84oBEf_brf41imS

1. Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""2. Loading Data"""

df = pd.read_csv("heart.csv")

"""3.Data Exploration

df.head(): Displays the first few rows to understand the data structure.
"""

df.head()

"""df.info():
 Provides a summary of the DataFrame, including column names, non-null counts, and data types.
"""

df.info()

"""df.describe(): Generates descriptive statistics of the numerical columns."""

df.describe()

"""df.shape: Shows the number of rows and columns in the DataFrame"""

df.shape

"""df.isnull().sum(): Checks for and counts missing values in each column."""

df.isnull().sum()

"""df.target.value_counts(): Displays the distribution of the target variable"""

plt.figure(figsize=(40, 18))
sns.boxplot(df)
plt.title('Box Plot of feature')
plt.show()

# Checking the outlier counts
def outlier_count(df, col):
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    return len(outliers)

cols = ['trestbps', 'fbs', 'thalach', 'oldpeak', 'ca', 'thal']
for col in cols:
    outlier_num = outlier_count(df, col)
    print(f"Number of outliers in {col}: {outlier_num}")

#Capping the outliers to lower or upper bound
def cap_outliers(df, col):
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])
    return df

cols = ['trestbps', 'fbs', 'thalach', 'oldpeak', 'ca', 'thal']
for col in cols:
    df = cap_outliers(df, col)

df.target.value_counts()

"""3. Handle Class Imbalance"""

X=df.drop('target',axis=1)
y=df['target']

from imblearn.over_sampling import SMOTE

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X, y = smote.fit_resample(X, y)

"""4. Split Data and Suppress Warnings"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Suppress warnings
import warnings
warnings.filterwarnings("ignore")

""" 6.Train and Evaluate Models"""

# Initialize models
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "SVC": SVC(random_state=42)
}

from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score

# Train and evaluate each model
results = {}
for model_name, model in models.items():
    print(f"Training {model_name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calculate evaluation metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results[model_name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }
    print(f"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}")
    print("-" * 30)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))

for name, model in models.items():
    # Get probability scores (needed for ROC curve)
    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:, 1]
    elif hasattr(model, "decision_function"): # For models like SVC
        y_proba = model.decision_function(X_test)
    else:
        # Skip models that don't provide probabilities or decision functions
        print(f"Skipping ROC curve for {name} (no predict_proba or decision_function)")
        continue

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random') # Random guess line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(True)
plt.show()

"""7. Save Models"""

import pickle

# Get the trained Random Forest model
random_forest_model = models["Random Forest"]

# Save the Random Forest model to a pickle file
filename_rf = 'random_forest_Heart_Disease_model.pkl'
pickle.dump(random_forest_model, open(filename_rf, 'wb'))

print(f"Random Forest model saved to {filename_rf}")

